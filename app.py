# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mjjIVi6T2hHTcNWGXS7OeFe-FLMfz5sD
"""

import streamlit as st
import pandas as pd
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, matthews_corrcoef, roc_auc_score

# 1. Page Setup
st.set_page_config(page_title="Mobile Price App", page_icon="ðŸ“±", layout="wide")
st.title("ðŸ“± Mobile Price Classification")

# 2. Sidebar: Model Selection & Data Download
st.sidebar.header("Configuration")
model_name = st.sidebar.selectbox("Select Model", ["Logistic Regression", "Decision Tree", "KNN", "Naive Bayes", "Random Forest", "XGBoost"])

# Try to provide the Test Data for download
try:
    with open("test_data.csv", "rb") as file:
        st.sidebar.download_button("ðŸ“¥ Download Test Data", file, "test_data.csv", "text/csv")
except FileNotFoundError:
    st.sidebar.warning("test_data.csv not found on server.")

# 3. Load Model & Scaler
@st.cache_resource
def load_model(name):
    scaler = joblib.load('models/scaler.pkl')
    model = joblib.load(f"models/{name.replace(' ', '_').lower()}.pkl")
    return model, scaler

try:
    model, scaler = load_model(model_name)
except:
    st.error("Error: Models not found. Please upload 'models/' folder to GitHub.")
    st.stop()

# 4. Main App: Upload & Predict
uploaded_file = st.file_uploader("Upload your CSV file", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)

    # Preprocessing
    X_test = df.drop('price_range', axis=1) if 'price_range' in df.columns else df
    y_true = df['price_range'] if 'price_range' in df.columns else None

    # Scale Data if needed (Logistic/KNN)
    if model_name in ["Logistic Regression", "KNN"]:
        X_test = scaler.transform(X_test)

    # Predict
    y_pred = model.predict(X_test)
    y_prob = model.predict_proba(X_test) # Required for AUC

    # 5. Display Results
    st.subheader(f"Results for {model_name}")

    if y_true is not None:
        # Calculate Metrics
        acc = accuracy_score(y_true, y_pred)
        auc = roc_auc_score(y_true, y_prob, multi_class='ovr')
        prec = precision_score(y_true, y_pred, average='weighted')
        rec = recall_score(y_true, y_pred, average='weighted')
        f1 = f1_score(y_true, y_pred, average='weighted')
        mcc = matthews_corrcoef(y_true, y_pred)

        # Show Metrics in Columns (Clean Layout)
        col1, col2, col3, col4, col5, col6 = st.columns(6)
        col1.metric("Accuracy", f"{acc:.2f}")
        col2.metric("AUC", f"{auc:.2f}")
        col3.metric("Precision", f"{prec:.2f}")
        col4.metric("Recall", f"{rec:.2f}")
        col5.metric("F1 Score", f"{f1:.2f}")
        col6.metric("MCC", f"{mcc:.2f}")

        # Confusion Matrix
        col_graph, col_text = st.columns([1, 2])
        with col_graph:
            st.write("##### Confusion Matrix")
            cm = confusion_matrix(y_true, y_pred)
            fig, ax = plt.subplots(figsize=(3, 3))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
            st.pyplot(fig)
    else:
        st.success("Predictions generated successfully!")

    # Show Data
    st.write("##### Prediction Data")
    df['Predicted_Price'] = y_pred
    st.dataframe(df.head())